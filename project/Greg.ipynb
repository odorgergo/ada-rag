{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from langdetect import detect, detect_langs\n",
    "from nltk.corpus import XMLCorpusReader\n",
    "import numpy as np\n",
    "from nltk.corpus import XMLCorpusReader\n",
    "\n",
    "def translate(x):\n",
    "    try:\n",
    "        t=detect(x)\n",
    "    except:\n",
    "        t=np.nan\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We received feedback that the low number of german tweets might be because langdetect cannot properly detect the swiss german dialenct. To test this, we downloaded a swiss german corpus from http://kitt.cl.uzh.ch/kitt/noah/corpus. The first corpus is downloaded from swiss german blogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"s ' gaht nüme lang\",\n",
       " 'hallo mitenand',\n",
       " 'zerscht mal : ich han en neue Blog müesse erstelle , will dr Andr gspunne het',\n",
       " 'alsoo',\n",
       " 'ich gah scho bald mal']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blick = XMLCorpusReader(\".\" ,'blogs.xml')\n",
    "swiss_german_text=\" \".join(blick.words()).split(\" . \")\n",
    "swiss_german_text[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use langdetect on each sentance and achieve a reasoably high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8250510551395507"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(sum(list(map(lambda x: translate(x)=='de',swiss_german_text))))/len(swiss_german_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is even higher on a swiss german newspaper from Zurich. This proves that the swiss german dialect is not an issue, but also warns us that langdetect might be less reliable on online (gramatically less correct) text such as twitter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9593984962406015"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blick = XMLCorpusReader(\".\" ,'blick.xml')\n",
    "swiss_german_text=\" \".join(blick.words()).split(\" . \")\n",
    "float(sum(list(map(lambda x: translate(x)=='de',swiss_german_text))))/len(swiss_german_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_root]",
   "language": "python",
   "name": "conda-env-my_root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
